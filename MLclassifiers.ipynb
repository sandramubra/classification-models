{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Sandra Munoz Braceras\n",
    "# created: 2020-11-24\n",
    "# last modified: 2020-12-05\n",
    "# purpose: ML models to classify types of a disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the packages and functions that will be used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV,train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset with the RNA-Seq Data of samples from different types of a disease\n",
    "df = pd.read_csv(\"data_for_ML_project.csv\",index_col=0)\n",
    "# Explore the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The alignment identified',str(df.shape[1]-1),'genes using the hg38 assembly of the human genome.'\n",
    "     '\\nThere are',df.shape[0],'samples from',str(len(df.types.unique())),'different types of the disease:' )\n",
    "number_per_type = {}\n",
    "for i in df.types:\n",
    "    if i in number_per_type.keys():\n",
    "        number_per_type[i] += 1\n",
    "    else:\n",
    "        number_per_type[i] = 1\n",
    "for k, v in number_per_type.items():\n",
    "    print(v,'of',k,', ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the dataframe, create an array with the unlabelled data (counts of gene reads) \n",
    "# and other with the labels (types of disease)\n",
    "df_data = df.drop(columns=[\"types\"])\n",
    "np_original_data = df_data.values\n",
    "df_labels = df[\"types\"]\n",
    "np_labels = df_labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined functions \n",
    "These functions will be used later for the random forest and the svm model to visualize the scores and parameters of the different models creted by GridSearchCV and to visualize the performance of the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting_best(clf):\n",
    "    '''visualize the scores and parameters of the different models creted by GridSearchCV'''\n",
    "    print('SUMMARY OF RESULTS WITH DIFFERENT PARAMETERS:')\n",
    "    all_param = clf.cv_results_['params']\n",
    "    all_means = clf.cv_results_['mean_test_score']\n",
    "    all_stds = clf.cv_results_['std_test_score']\n",
    "    for param, mean, std in zip(all_param, all_means, all_stds):\n",
    "        print(param,'->',str(round(mean,2)),'+/-',str(round(std,2)))\n",
    "    print('\\n the best parameters are:',clf.best_params_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_best(clf, y, X, train_or_test):\n",
    "    '''visualize the performance of the best model'''\n",
    "    print('PERFORMANCE OF THE BEST MODEL:')\n",
    "    y_true, y_pred = y, clf.predict(X)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    # evaluate the performance of the best model\n",
    "    best_model = clf.best_estimator_\n",
    "    if train_or_test == 'test':\n",
    "        print('Confusion matrix for the testing set:')\n",
    "    elif train_or_test == 'train':\n",
    "        print('Confusion matrix for the training set:')\n",
    "    confusion_matrices(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrices(true_labels, predicted_labels):\n",
    "    '''display confusion matrices'''\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(9, 3))\n",
    "    for i in ['true','pred']:\n",
    "        if i == 'true':\n",
    "            j = 0\n",
    "            title = 'Recall scores in diagonal'\n",
    "        elif i == 'pred':\n",
    "            j = 1\n",
    "            title = 'Precision scores in diagonal' \n",
    "        cm = confusion_matrix(true_labels,predicted_labels, normalize=i)\n",
    "        df_cm = pd.DataFrame(cm,index=['1','2','3','4','5'],columns=['1','2','3','4','5'])\n",
    "        sns.heatmap(df_cm, annot=True,ax=axes[j], cmap='gist_heat', center=0.5)\n",
    "        axes[j].set_title(title,fontsize = 11, fontweight = 'bold')\n",
    "        axes[j].set_ylabel('true types')\n",
    "        axes[j].set_xlabel('predicted types')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a Random Forest with the original data (no need for normalization or dim reduction)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several parameters for the Random Forest model will be tested \n",
    "# by a GridSearch with Cross Validation \n",
    "rf_hyperpar = {\n",
    "    'n_estimators': [65, 95, 125], #between 64 and 128 suggested\n",
    "    'max_depth': [15, 30],\n",
    "    'max_features': [2000, 'sqrt'],\n",
    "    'class_weight':['balanced'],\n",
    "    'max_samples': [0.5, 0.9],\n",
    "    'random_state':[0]\n",
    "    }\n",
    "\n",
    "# Create training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(np_original_data, np_labels, test_size=0.20, stratify=np_labels, random_state=0)\n",
    "\n",
    "# Search of the best parameters \n",
    "rf_clf = GridSearchCV(RandomForestClassifier(), rf_hyperpar, scoring='f1_weighted', cv = 5, verbose = 3, n_jobs = -1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "selecting_best(rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_best(rf_clf,y_test,X_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_best(rf_clf,y_train,X_train,'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification of the most important genes for the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an idea of the 10 most important genes for the classification\n",
    "best_model = rf_clf.best_estimator_\n",
    "important_features = best_model.feature_importances_\n",
    "indices = np.argsort(important_features)[::-1]\n",
    "genes= []\n",
    "importances=[]\n",
    "\n",
    "for f in range(20):\n",
    "    genes.append('gene_'+str(indices[f]+1))\n",
    "    importances.append(important_features[indices[f]])\n",
    "sns.barplot(y=genes, x=importances, orient='h', palette = 'Blues_r')\n",
    "sns.despine()\n",
    "plt.xlabel('Importance')\n",
    "plt.title('20 most important genes for the model classification',\n",
    "        fontsize = 12, fontweight = 'bold', y=1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(16, 3))\n",
    "for i in range(5):\n",
    "    sns.boxplot(ax=axes[i], x='types', y=genes[i], data=df, order=['type_1','type_2','type_3','type_4','type_5'], palette = 'Spectral')\n",
    "    axes[i].set_ylabel('Expression levels')\n",
    "    axes[i].set_xlabel('Disease types')\n",
    "    axes[i].set_xticks([0,1,2,3,4])\n",
    "    axes[i].set_xticklabels([1,2,3,4,5])\n",
    "    axes[i].set_title(genes[i],fontsize = 10, fontweight = 'bold', y=0.99)\n",
    "    sns.despine()\n",
    "fig.suptitle('5 most important genes for the model classification',\n",
    "        fontsize = 12, fontweight = 'bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizaton of the data for models other than Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "np_normalized_data = scaler.fit_transform(np_original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction using PCA to reduce the 59366 features (genes) \n",
    "# to a few principal components that describe x% of the variance'''\n",
    "# I use PCA instead of UMAP because I'll be interested in the interpretation of the results\n",
    "for i in [0.2,0.5,0.8,0.9,0.95,0.99,0.999]:\n",
    "    dim_reducer = PCA(n_components=i,svd_solver='full', random_state=0)\n",
    "    np_reduced_data = dim_reducer.fit_transform(np_normalized_data)\n",
    "    print(str(np_reduced_data.shape[1]),'principal components are needed to explain', str(i*100),'% of the variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several parameters for the Random Forest model will be tested \n",
    "# by a GridSearch with Cross Validation \n",
    "for i in [15,138]:\n",
    "    dim_reducer = PCA(n_components=i,svd_solver='full', random_state=0)\n",
    "    np_reduced_data = dim_reducer.fit_transform(np_normalized_data)\n",
    "    print('-------SVM MODEL FOR',i,'DIMENSIONS------')\n",
    "\n",
    "    svm_hyperpar = {'kernel': ['linear', 'rbf'], 'class_weight' : ['balanced'], 'C' : [0.001,100],'random_state':[0]}\n",
    "\n",
    "    # Create training and testing subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np_reduced_data, np_labels, test_size=0.20, stratify=np_labels, random_state=0)\n",
    "    # Search of the best parameters \n",
    "    svm_clf = GridSearchCV(SVC(), svm_hyperpar, scoring='f1_weighted', cv = 5, verbose = 1, n_jobs = -1)\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "\n",
    "    selecting_best(svm_clf)\n",
    "    performance_best(svm_clf,y_test,X_test,'test')\n",
    "    performance_best(svm_clf,y_train,X_train,'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(0)\n",
    "\n",
    "# Transform the labels data to a binary one-hot encoding to be used by the network\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(df_labels)\n",
    "encoded_labels = np_utils.to_categorical(encoded_labels)\n",
    "\n",
    "# defining the cross validation method by a variation of KFold that returns stratified folds\n",
    "\n",
    "for i in [15, 138]:\n",
    "    dim_reducer = PCA(n_components=i,svd_solver='full', random_state=0)\n",
    "    np_reduced_data = dim_reducer.fit_transform(np_normalized_data)\n",
    "    print('-------ANN FOR',i,'DIMENSIONS------')   \n",
    "    # creating the ANN\n",
    "    #lists to build the heatmap\n",
    "    total_labels = []\n",
    "    total_predictions = []\n",
    "        \n",
    "    for j in range(5):\n",
    "        ann_model = Sequential()\n",
    "        ann_model.add(Dense(500, input_dim=i, activation='relu'))\n",
    "        ann_model.add(Dense(200, activation='relu'))\n",
    "        ann_model.add(Dense(5, activation='softmax'))\n",
    "        ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "        \n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            np_reduced_data, encoded_labels, test_size=0.20, stratify=encoded_labels, random_state=0)\n",
    "\n",
    "        ann_model.fit(X_train, y_train, epochs=10, batch_size=20)\n",
    "        predictions = ann_model.predict_classes(X_test)\n",
    "        total_predictions.extend(encoder.inverse_transform(predictions))\n",
    "\n",
    "        y_test = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
    "        total_labels.extend(encoder.inverse_transform(y_test))\n",
    "    \n",
    "    confusion_matrices(total_labels,total_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
